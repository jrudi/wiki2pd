{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wiki2pd:\n",
    "    def __init__(self,**kwargs):\n",
    "        self.parser = kwargs.get('parser','html.parser')\n",
    "        self.decimal = kwargs.get('decimal','.')\n",
    "        self.thousands = kwargs.get('thousands',',')\n",
    "    # Arguments:\n",
    "    # url: The URL where the Wikipedia Tables are present\n",
    "    # optional:\n",
    "    # table_class: string - The CSS class in which the table is nested. Default: 'wikitable'\n",
    "    # tables: list - The tables, which will be downloaded. Default: [], meaning all tables\n",
    "    def load_tables(self,url,**kwargs):\n",
    "        self.table_class = kwargs.get('table_class','wikitable')\n",
    "        #self.tables = kwargs.get('n_tables',[])\n",
    "        \n",
    "        soup = BeautifulSoup(requests.get(url).text, self.parser)\n",
    "        tables = soup.find_all(class_=self.table_class)\n",
    "        tables_df = []\n",
    "        for tb in tables:\n",
    "            if len(tb.find_all(class_='wikitable'))>0 or 'collapsible' in tb['class'] or len(tb.find_all('tr'))<2:\n",
    "                continue\n",
    "            tb = self.fix_rowspans(tb)\n",
    "            \n",
    "            #Remove all \"sup\" tags\n",
    "            for tag in tb.find_all('sup'):\n",
    "                tag.decompose()\n",
    "                \n",
    "            #Print the capture\n",
    "            caption = tb.find('caption')\n",
    "            if caption != None:\n",
    "                print(caption.text)\n",
    "            else:\n",
    "                print(\"No Caption\")\n",
    "            \n",
    "            #Get all rows from the table\n",
    "            data = tb.find_all('tr')\n",
    "            \n",
    "            #Get the header from the first row\n",
    "            headers_text = [x.text.strip() for x in data[0].find_all('th')]\n",
    "            df = pd.DataFrame(columns=headers_text)\n",
    "            \n",
    "            ctr=0\n",
    "            for row in data[1:]:\n",
    "                #Get the row data\n",
    "                data_row = dict(zip(headers_text, [x.text.strip() for x in row.find_all(['td','th'])]))\n",
    "            \n",
    "                if len(data_row)!=len(headers_text):\n",
    "                    1+1\n",
    "                    #print(data_row)\n",
    "                    #print(\"Error on row %s: row length (%s) and header length (%s) don't match\"%(ctr,len(data_row),len(headers_text)))\n",
    "                else:\n",
    "                    df = df.append(data_row,ignore_index=True)\n",
    "            \n",
    "                ctr+=1\n",
    "            tables_df.append(df)\n",
    "        \n",
    "        #self.tables = tables_df\n",
    "        return tables_df      \n",
    "    \n",
    "    \n",
    "    def fix_rowspans(self,table):\n",
    "        tmp = table.find_all('tr')\n",
    "        first = tmp[0]\n",
    "        allRows = tmp[1:-1]\n",
    "        headers = [header.get_text() for header in first.find_all('th')]\n",
    "        results = [[data.get_text() for data in row.find_all('td')] for row in allRows]\n",
    "        rowspan = []\n",
    "\n",
    "        for no, tr in enumerate(allRows):\n",
    "            tmp = []\n",
    "            for td_no, data in enumerate(tr.find_all('td')):\n",
    "                print  data.has_key(\"rowspan\")\n",
    "                if data.has_key(\"rowspan\"):\n",
    "                    rowspan.append((no, td_no, int(data[\"rowspan\"]), data.get_text()))\n",
    "\n",
    "\n",
    "        if rowspan:\n",
    "            for i in rowspan:\n",
    "                # tr value of rowspan in present in 1th place in results\n",
    "                for j in xrange(1, i[2]):\n",
    "                    #- Add value in next tr.\n",
    "                    results[i[0]+j].insert(i[1], i[3])   \n",
    "        return results\n",
    "    \n",
    "    \n",
    "    def apply_info(self,df,info):\n",
    "        ll = list(df.columns)\n",
    "        for col in range(len(ll)):\n",
    "            if info[col].get('drop'):\n",
    "                df = df.drop(columns=ll[col])\n",
    "                continue\n",
    "              \n",
    "            if info[col].get('footnotes'):                \n",
    "                df[ll[col]] = df[ll[col]].apply(lambda x: re.sub(r'\\[\\d+\\]','',x))\n",
    "                \n",
    "            if info[col].get('type')=='numeric':\n",
    "                new_col = df[ll[col]].apply(lambda x: x.replace(self.thousands,''))\n",
    "                if info[col].get('unit')!=None:\n",
    "                    new_col = new_col.apply(lambda x: x.replace(info[col].get('unit'),''))\n",
    "                df[ll[col]] = pd.to_numeric(new_col,errors='coerce')\n",
    "                if info[col].get('nan')!= None:\n",
    "                    df[ll[col]] = df[ll[col]].fillna(info[col].get('nan'))\n",
    "                    \n",
    "            if info[col].get('name')!= None:\n",
    "                df = df.rename(columns={ll[col]:info[col]['name']})\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = [{'name':'Land'},\n",
    "        {'name':'Rang','type':'numeric','nan':0},\n",
    "        {'name':'GRPEUR','type':'numeric',},\n",
    "        {'name':'GRPUSD','type':'numeric'},\n",
    "        {'name':'Comparison','drop':True}]\n",
    "\n",
    "info2 = [{'name':'Rang'},\n",
    "         {'drop':True},\n",
    "         {'drop':True},\n",
    "         {'drop':True},\n",
    "         {'name':'GDP_Nominal','type':'numeric'},\n",
    "         {'footnotes':True},\n",
    "         {'name':'Population','type':'numeric'},\n",
    "         {'name': 'GDP_per_Capita','type':'numeric'},\n",
    "         {'drop':True}]\n",
    "\n",
    "info3 = [{},{},{},{'type':'numeric','unit':'$'},{},{'drop':True}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest-grossing films\n",
      "\n",
      "Highest-grossing films as of 2019 adjusted for inflation\n",
      "\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "High-grossing films by year of release\n",
      "\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "HUHU\n",
      "Timeline of the highest-grossing film record\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#url = 'https://en.wikipedia.org/wiki/List_of_German_states_by_GRP_per_capita'\n",
    "#url = 'https://en.wikipedia.org/wiki/List_of_country_subdivisions_by_GDP_over_200_billion_USD'\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_highest-grossing_films'\n",
    "wiki = Wiki2pd()\n",
    "df = wiki.load_tables(url)\n",
    "\n",
    "#df = wiki.tables[1]\n",
    "#df = wiki.apply_info(df,info3)\n",
    "\n",
    "#df\n",
    "\n",
    "#url = 'https://en.wikipedia.org/wiki/List_of_European_regions_by_GDP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info Object\n",
    "\n",
    "Options:\n",
    "1. Drop a column\n",
    "2. Change name of a column\n",
    "3. Change type of a column to numeric\n",
    "    3.1 Fill NaN values\n",
    "    3.2 Remove Currency icons\n",
    "    \n",
    "Structure:\n",
    "For a table with **n** columns, you need a list with **n** dictionaries. If the dict is empty, the data will just be converted as String with out any modifications.\n",
    "\n",
    "### 1. Dropping a column\n",
    "Declare `'drop':True`, if you want to remove the column. Default = False\n",
    "\n",
    "### 2. Change name of a column\n",
    "Declare `'name':'<new_name>'`, to give the column a new name. If you leave this out, the column keeps its original name, which can be sometimes annoying, when column names are very similar or long.\n",
    "\n",
    "Example:\n",
    "\n",
    "`info = [\n",
    "        {'name':'Land'},\n",
    "        {'name':'Rang','type':'numeric','nan':0},\n",
    "        {'name':'GRPEUR','type':'numeric',},\n",
    "        {'name':'GRPUSD','type':'numeric'},\n",
    "        {'name':'Comparison','drop':True}\n",
    "        ]\n",
    "`\n",
    "\n",
    "### 3. Change type of a column to numeric\n",
    "\n",
    "Changes the type of the Series to a numeric one, depending on the input. It removes the thousands-delimiter (normally ',', in Germany '.'). The delimiter can be selected, when creating the Wiki2pd instance. This function uses pandas `pd.to_numeric()` with `errors='coerce'`, so all errors will become NaN. Simply set `'type':'numeric'`\n",
    "\n",
    "Example:  \n",
    "\n",
    "`info = [\n",
    "        {'name':'Land'},\n",
    "        {'type':'numeric',},\n",
    "        {'name':'GRPUSD','type':'numeric'}\n",
    "        ]\n",
    "`\n",
    "\n",
    "####    3.1 Fill NaN values\n",
    "Only works, if `'type':'numeric'` is active.\n",
    "If you want to later handle NaN values yourself, you can leave this deactivated. If you just want to set NaN values to a certain value, you can use `'nan':<Value>`\n",
    "\n",
    "Example: \n",
    "\n",
    "`info = [  \n",
    "        {'name':'Land'},\n",
    "        {'name':'Rang','type':'numeric','nan':0}  \n",
    "        ]  \n",
    "`\n",
    "\n",
    "#### 3.2 Remove Units\n",
    "Only works, if `'type':'numeric'` is active.\n",
    "If the column contains a unit in some or all rows, `'unit':<UNIT>`removes this unit. Works by simply replacing the String with an empty String. \n",
    "\n",
    "Example:  \n",
    "\n",
    "`info = [\n",
    "        {},\n",
    "        {'type':'numeric','unit':'â‚¬'},\n",
    "        {},\n",
    "        {'drop':True}\n",
    "        ]\n",
    "`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_rowspans = []\n",
    "for row in table.findAll(\"tr\"):\n",
    "    cells = row.findAll([\"th\", \"td\"])\n",
    "\n",
    "    if len(saved_rowspans) == 0:\n",
    "        saved_rowspans = [None for _ in cells]\n",
    "        \n",
    "for index, cell in enumerate(cells):\n",
    "    if cell.has_key(\"rowspan\"):\n",
    "        rowspan_data = {\n",
    "            'rows_left': int(cell[\"rowspan\"]),\n",
    "            'value': cell,\n",
    "        }\n",
    "        saved_rowspans[index] = rowspan_data\n",
    "        \n",
    "elif len(cells) != len(saved_rowspans):\n",
    "    for index, rowspan_data in enumerate(saved_rowspans):\n",
    "        if rowspan_data is not None:\n",
    "            # Insert the data from previous row; decrement rows left\n",
    "            cells.insert(index, rowspan_data['value'])\n",
    "\n",
    "            if saved_rowspans[index]['rows_left'] == 1:\n",
    "                saved_rowspans[index] = None\n",
    "            else:\n",
    "                saved_rowspans[index]['rows_left'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_highest-grossing_films'\n",
    "soup = BeautifulSoup(requests.get(url).text, 'html.parser')\n",
    "\n",
    "tables = soup.find_all(class_=\"wikitable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table class=\"wikitable\" style=\"margin:auto; width:100%;\">\n",
      "<tbody><tr>\n",
      "<th style=\"width:5%;\">Rank\n",
      "</th>\n",
      "<th style=\"width:30%;\">Series\n",
      "</th>\n",
      "<th style=\"width:11%;\">Total worldwide gross\n",
      "</th>\n",
      "<th style=\"width:5%;\">No. of films\n",
      "</th>\n",
      "<th style=\"width:11%;\">Average of films\n",
      "</th>\n",
      "<th style=\"width:38%;\">Highest-grossing film\n",
      "</th></tr></tbody></table>\n"
     ]
    }
   ],
   "source": [
    "print(tables[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = [1,2,3,4,5]\n",
    "xx[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
